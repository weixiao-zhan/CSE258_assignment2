{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip, json\n",
    "def parse(path):\n",
    "  g = gzip.open(path, 'r')\n",
    "  for l in g:\n",
    "    yield json.loads(l)\n",
    "\n",
    "data = []\n",
    "\n",
    "for review in parse(\"Software.json.gz\"):\n",
    "  data.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your list of strings\n",
    "documents = []\n",
    "for d in data: \n",
    "    strs = []\n",
    "    if 'summary' in d:\n",
    "        strs.append(d['summary'])\n",
    "    if 'reviewText' in d:\n",
    "        strs.append(d['reviewText'])\n",
    "    documents.append(\" \".join(strs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "indices_train = np.load('non-text-feature.npz')['indices_train']\n",
    "train_documents = [documents[i] for i in indices_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow_vectorizer = CountVectorizer()\n",
    "bow_vectorizer.fit(train_documents)\n",
    "bag_of_words = bow_vectorizer.transform(documents)\n",
    "from scipy import sparse\n",
    "sparse.save_npz(\"text-bag_of_words.npz\", bag_of_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_vectorizer.fit(train_documents)\n",
    "tfidf_matrix = tfidf_vectorizer.transform(documents)\n",
    "from scipy import sparse\n",
    "sparse.save_npz(\"text-tfidf.npz\", tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "100%|██████████| 459436/459436 [00:15<00:00, 28900.34it/s]\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "import fasttext.util\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "from functools import lru_cache\n",
    "\n",
    "# Load the reduced FastText model\n",
    "ft = fasttext.load_model('cc.en.300.bin')\n",
    "\n",
    "# Preprocessing and tokenization\n",
    "processed_docs = [\n",
    "    word_tokenize(doc.lower().translate(str.maketrans('', '', string.punctuation)))\n",
    "    for doc in documents\n",
    "]\n",
    "\n",
    "\n",
    "@lru_cache(maxsize=10000)\n",
    "def get_word_vector(word):\n",
    "    return ft.get_word_vector(word)\n",
    "\n",
    "# Function to get the vector for a document\n",
    "def get_doc_vector(doc):\n",
    "    vectors = np.array([get_word_vector(word) for word in doc])\n",
    "    return np.mean(vectors, axis=0) if vectors.size else np.zeros(ft.get_dimension())\n",
    "\n",
    "# Get document vectors\n",
    "word2vec = np.array([get_doc_vector(doc) for doc in tqdm(processed_docs)])\n",
    "\n",
    "# Now doc_vectors contains the vector representation of each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(459436, 300)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez_compressed('text-feature_word2vec.npz',\n",
    "    word2vec=word2vec\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
